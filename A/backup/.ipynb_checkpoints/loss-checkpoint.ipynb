{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea1310e-7a92-46f7-8edc-b54d45f55aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\lemai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\lemai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0414849d-23e9-4102-9234-a105be57c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SigmoidFocalLoss(\n",
    "    inputs: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    alpha: float = 0.25,\n",
    "    gamma: float = 2,\n",
    "    reduction: str = 'none'):\n",
    "\n",
    "    '''\n",
    "    - inputs, labels = [0|1]\n",
    "    \n",
    "    - alpha:\n",
    "    siêu tham số khác quyết định mức độ cân bằng giữa các lớp trong trường hợp mất cân bằng dữ liệu. \n",
    "    Nếu bạn muốn tập trung nhiều hơn vào lớp thiểu số, bạn có thể đặt giá trị alpha cao hơn cho lớp thiểu số.\n",
    "\n",
    "    - gamma:\n",
    "    siêu tham số quyết định mức độ tập trung của hàm mất mát vào các ví dụ khó phân loại. \n",
    "    Giá trị gamma cao hơn đặt nhiều trọng số hơn cho các ví dụ bị phân loại sai. Thường thì giá trị gamma được đặt trong khoảng từ 1 đến 5.\n",
    "\n",
    "    - reduction:\n",
    "    Tham số này xác định cách hàm mất mát được thu gọn qua toàn bộ mẫu dữ liệu. \n",
    "    Nó có thể có giá trị \"none\" (không thu gọn), \"mean\" (trung bình của các mất mát), hoặc \"sum\" (tổng của các mất mát).\n",
    "    '''\n",
    "\n",
    "    p = inputs # 0 or 1\n",
    "    bce_loss = F.binary_cross_entropy(inputs, labels, reduction=\"none\")\n",
    "    \n",
    "    p_t = p * labels + (1 - p) * (1 - labels) \n",
    "    # nếu p và labels (0 or 1) trừng nhau --> dự đoán đúng --> p_t = 1\n",
    "    # nếu p và labels (0 or 1) khác nhau --> dự đoán sai --> p_t = 0\n",
    "    \n",
    "    loss = bce_loss * ((1 - p_t) ** gamma)\n",
    "    '''\n",
    "    - loss có cùng hình dạng và kích thước với ce_loss. \n",
    "    Nó chứa các giá trị mất mát focal loss đã được điều chỉnh để tập trung vào các ví dụ khó phân loại.\n",
    "    '''\n",
    "\n",
    "    if alpha >= 0:\n",
    "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "        loss = alpha_t * loss\n",
    "\n",
    "    if reduction == \"mean\":\n",
    "        loss = loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        loss = loss.sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d288f754-e822-4366-a2d1-24276fdc52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_classifier(pred_classifier, labels_classifier):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    return loss_fn(pred_classifier, labels_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1b0861-9743-4492-846a-3d5ec66b24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_regressor(pred_regressor, labels_regressor):\n",
    "    mask = (labels_regressor != 0)\n",
    "    loss = ((pred_regressor - labels_regressor)**2)[mask].sum() / mask.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187baf8f-b0fb-445c-b2f7-3a786bf1ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_softmax(inputs, labels, device):\n",
    "    mask = (labels != 0)\n",
    "    n, aspect, rate = inputs.shape\n",
    "    num = 0\n",
    "    loss = torch.zeros(labels.shape).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    for i in range(aspect):\n",
    "        label_i = labels[:, i].clone()\n",
    "        label_i[label_i != 0] -= 1\n",
    "        label_i = label_i.type(torch.LongTensor).to(device)\n",
    "        loss[:, i] = loss_fn(inputs[:, i, :], label_i)\n",
    "    loss = loss[mask].sum() / mask.sum()\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
